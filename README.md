#  Twitter Sentiment Analysis 

## Problem Statement

It would give a great value to companies when they launch products and understand the sentiment of users through __different tweets__ and __comments__. This guarantees that the companies understand the behavior of the customers and make changes based on the __sentiment__ and therefore, take actions based on insights from the comments and improve the __overall revenue__ of the company respectively. 


## Machine Learning and Data Science

Using machine learning techniques and text extraction, we are going to be predicting the sentiment of the text whether it is positive or negative. First, we would be working with the text and check the different words present in the text and once we understand them, we would be performing the machine learning analysis respectively and use the deep neural networks. Then, we are going to be taking those values and performing machine learning operations and getting the predictions as to whether they are positive or negative. 

## Natural Language Processing (NLP)
We would be using the natural language processing that is required when doing the machine learning analysis. Performing the natural language processing ensures that the words that are present are converted into mathematical vectors that are used for different macihne learning models for prediction. Once the mathematical vectors are converted into different vectors, they are given for the machine learning models for prediction respectively. Therefore, with the features that are present in the text along with some newly created features, the machine learning and deep learnimg models would be using those techniques and ensures that they are getting the best outputs respectively. 

## Exploratory Data Analysis (EDA)

* After performing __exploratory data analysis__, it could be seen based on the results that there are comparatively more number of neutral sentences compared to either positive or negative sentiments. 
* With the use of __word clouds__, it could be seen that words such as good, awesome and great were used most frequently.
* On the contrary, it could ben seen for the negative __word cloud__ that words such as hate, sorry and sad were used most frequently. 

## Vectorizers 

It is important to use vectorizers that are important for machine learning. Therefore, a given text which is in the form of a string is converted into a vectorial representation that is what is being used by machine learning models for prediction. Below are some of the vectorizers that were used in the process of converting a text into a mathematical representation. 

* [__Count Vectorizer__](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)
* [__Tfidf Vectorizer__](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)

## Hyperparameter Tuning 

Once we understand the different machine learning models, we are going to use the hyperparameter tuning which ensures that good set of hyperparameters are selected and this would result in machine learning models that creates the best results respectively. Once we get those important results for the hyperparameters, we are going to use them and ensure that we are getting the best accuracy for the machine learning models. We are going to learn the different hyperparameters and how they influence the machine learning models and the outcome of different problem statements. Therefore, let us now get an understanding of the project and see how these machine learning models are using for production respectively. 

## Conclusion
It would be a good idea to use some tools such as wordcloud when we are doing Natural Language Processing (NLP) to ensure that we are getting the best results for predictions respectively. We would be able to understand the frequently occurring words from the less frequently occurring words by the size of the words that are plotted in the wordcloud respectively.
Steps should be taken to ensure that the model does not overfit or underfit. This ensures that the best predictions are being generated and therefore, we are going to get the best outputs respectively.
Standarizing the text and ensuring that the values lie between 0 and 1 would be good as this would allow the machine learning models to generate weights that are quite small rather than having different weight range values.
